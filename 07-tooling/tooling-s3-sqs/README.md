# Tooling - S3 and SQS

We're using serverless-offline, nodemom packages to run lamba locally
